name: Deploy to EC2

on:
  workflow_call:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        type: string
        default: "dev"
      aws_region:
        description: 'AWS region to deploy to'
        required: true
        type: string
        default: "eu-north-1"
      image_tag:
        description: 'Docker image tag to deploy'
        required: true
        type: string
      instance_ip:
        description: 'EC2 instance IP address'
        required: true
        type: string

jobs:
  deploy:
    runs-on: ubuntu-latest
    # These permissions are needed to interact with GitHub's OIDC Token endpoint
    permissions:
      id-token: write  # Required for requesting the JWT
      contents: read   # Required for actions/checkout
    env:
      AWS_REGION: ${{ inputs.aws_region }}
      ENVIRONMENT: ${{ inputs.environment }}
      SECRETS_PREFIX: "/${{ inputs.environment }}/backend"
      IMAGE_TAG: ${{ inputs.image_tag }}
      INSTANCE_IP: ${{ inputs.instance_ip }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ vars.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}
          mask-aws-account-id: true

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      - name: Get secrets from AWS Secrets Manager
        id: secrets
        run: |
          # Fetch database URL
          DATABASE_URL_SECRET=$(aws secretsmanager get-secret-value --secret-id "${{ env.SECRETS_PREFIX }}/DATABASE_URL" --query SecretString --output text || echo "")
          if [ -z "$DATABASE_URL_SECRET" ]; then
            echo "Using DATABASE_URL from GitHub secrets as fallback"
            DATABASE_URL="${{ secrets.DATABASE_URL }}"
          else
            echo "Using DATABASE_URL from AWS Secrets Manager"
            DATABASE_URL="$DATABASE_URL_SECRET"
          fi

          # Fetch Supabase URL
          SUPABASE_URL_SECRET=$(aws secretsmanager get-secret-value --secret-id "${{ env.SECRETS_PREFIX }}/SUPABASE_URL" --query SecretString --output text || echo "")
          if [ -z "$SUPABASE_URL_SECRET" ]; then
            echo "Using SUPABASE_URL from GitHub secrets as fallback"
            SUPABASE_URL="${{ secrets.SUPABASE_URL }}"
          else
            echo "Using SUPABASE_URL from AWS Secrets Manager"
            SUPABASE_URL="$SUPABASE_URL_SECRET"
          fi

          # Fetch Supabase service role key
          SUPABASE_KEY_SECRET=$(aws secretsmanager get-secret-value --secret-id "${{ env.SECRETS_PREFIX }}/SUPABASE_SERVICE_ROLE_KEY" --query SecretString --output text || echo "")
          if [ -z "$SUPABASE_KEY_SECRET" ]; then
            echo "Using SUPABASE_SERVICE_ROLE_KEY from GitHub secrets as fallback"
            SUPABASE_KEY="${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}"
          else
            echo "Using SUPABASE_SERVICE_ROLE_KEY from AWS Secrets Manager"
            SUPABASE_KEY="$SUPABASE_KEY_SECRET"
          fi

          # Store secrets securely in environment variables
          echo "DATABASE_URL=$DATABASE_URL" >> $GITHUB_ENV
          echo "SUPABASE_URL=$SUPABASE_URL" >> $GITHUB_ENV
          echo "SUPABASE_KEY=$SUPABASE_KEY" >> $GITHUB_ENV

      - name: Validate instance ID
        id: validate-instance
        run: |
          INSTANCE_ID="${{ vars.EC2_INSTANCE_ID }}"

          # Validate instance ID
          if [ -z "$INSTANCE_ID" ]; then
            echo "::error::EC2_INSTANCE_ID is not set in GitHub variables. Please add this variable with a valid EC2 instance ID."
            exit 1
          fi

          # Check if instance ID is in the correct format (i-xxxxxxxxxxxxxxxxx)
          if [[ ! "$INSTANCE_ID" =~ ^i-[a-zA-Z0-9]{8,17}$ ]]; then
            echo "::error::Invalid EC2 instance ID format: $INSTANCE_ID. Expected format: i-xxxxxxxxxxxxxxxxx"
            exit 1
          fi

          echo "instance_id=$INSTANCE_ID" >> $GITHUB_OUTPUT
          echo "Using EC2 instance: $INSTANCE_ID"

      - name: Deploy to EC2 using SSM
        run: |
          # Use a simpler approach with multiple SSM commands
          INSTANCE_ID="${{ steps.validate-instance.outputs.instance_id }}"
          REGION="${{ env.AWS_REGION }}"

          # Create the docker-compose content
          DOCKER_COMPOSE=$(cat << EOF
          version: '3'
          services:
            backend:
              image: ${{ steps.login-ecr.outputs.registry }}/vista-backend-${{ env.ENVIRONMENT }}:${{ env.IMAGE_TAG }}
              ports:
                - "80:8000"
              restart: always
              environment:
                - DATABASE_URL=${{ env.DATABASE_URL }}
                - SUPABASE_URL=${{ env.SUPABASE_URL }}
                - SUPABASE_SERVICE_ROLE_KEY=${{ env.SUPABASE_KEY }}
                - ENVIRONMENT=${{ env.ENVIRONMENT }}
          EOF
          )

          # Step 1: Create directory
          echo "Creating project directory..."
          aws ssm send-command \
            --instance-ids "$INSTANCE_ID" \
            --document-name "AWS-RunShellScript" \
            --parameters '{"commands":["mkdir -p ~/project-vista-app"]}' \
            --output text \
            --region "$REGION"

          # Step 2: Create docker-compose file (properly escaped)
          echo "Creating docker-compose.yml on instance..."
          # Escape the docker-compose content for JSON
          DOCKER_COMPOSE_ESCAPED=$(echo "$DOCKER_COMPOSE" | jq -Rs .)
          # Remove the outer quotes that jq adds
          DOCKER_COMPOSE_ESCAPED="${DOCKER_COMPOSE_ESCAPED:1:-1}"

          aws ssm send-command \
            --instance-ids "$INSTANCE_ID" \
            --document-name "AWS-RunShellScript" \
            --parameters "{\"commands\":[\"echo '$DOCKER_COMPOSE_ESCAPED' > ~/project-vista-app/docker-compose.yml\"]}" \
            --output text \
            --region "$REGION"

          # Step 3: Run deployment commands
          echo "Running deployment..."
          aws ssm send-command \
            --instance-ids "$INSTANCE_ID" \
            --document-name "AWS-RunShellScript" \
            --parameters '{
              "commands":[
                "cd ~/project-vista-app",
                "export AWS_REGION='${{ env.AWS_REGION }}'",
                "export ECR_REGISTRY='${{ steps.login-ecr.outputs.registry }}'",
                "aws ecr get-login-password --region '${{ env.AWS_REGION }}' | docker login --username AWS --password-stdin '${{ steps.login-ecr.outputs.registry }}'",
                "docker-compose pull",
                "docker-compose down || true",
                "docker-compose up -d",
                "echo \"Deployment completed successfully\""
              ]
            }' \
            --output text \
            --cloud-watch-output-config CloudWatchOutputEnabled=true \
            --region "$REGION"

          echo "Deployment commands sent to instance $INSTANCE_ID"

      - name: Verify deployment
        run: |
          INSTANCE_ID="${{ steps.validate-instance.outputs.instance_id }}"
          REGION="${{ env.AWS_REGION }}"
          INSTANCE_IP="${{ env.INSTANCE_IP }}"

          # Wait for the container to start
          echo "Waiting for container to start..."
          sleep 15

          # Check if the container is running
          echo "Checking if container is running..."
          COMMAND_ID=$(aws ssm send-command \
            --instance-ids "$INSTANCE_ID" \
            --document-name "AWS-RunShellScript" \
            --parameters '{"commands":["docker ps | grep vista-backend"]}' \
            --output text \
            --query "Command.CommandId" \
            --region "$REGION")

          # Wait for command to complete
          aws ssm wait command-executed \
            --command-id "$COMMAND_ID" \
            --instance-id "$INSTANCE_ID" \
            --region "$REGION"

          # Get command output
          CONTAINER_STATUS=$(aws ssm get-command-invocation \
            --command-id "$COMMAND_ID" \
            --instance-id "$INSTANCE_ID" \
            --region "$REGION" \
            --query "StandardOutputContent" \
            --output text)

          echo "Container status: $CONTAINER_STATUS"

          # Check if the API is responding
          echo "Checking if API is responding..."
          HEALTH_COMMAND_ID=$(aws ssm send-command \
            --instance-ids "$INSTANCE_ID" \
            --document-name "AWS-RunShellScript" \
            --parameters '{"commands":["curl -s http://localhost/api/health"]}' \
            --output text \
            --query "Command.CommandId" \
            --region "$REGION")

          # Wait for command to complete
          aws ssm wait command-executed \
            --command-id "$HEALTH_COMMAND_ID" \
            --instance-id "$INSTANCE_ID" \
            --region "$REGION"

          # Get health check output
          HEALTH_CHECK=$(aws ssm get-command-invocation \
            --command-id "$HEALTH_COMMAND_ID" \
            --instance-id "$INSTANCE_ID" \
            --region "$REGION" \
            --query "StandardOutputContent" \
            --output text)

          echo "Health check response: $HEALTH_CHECK"

          # Verify health check response
          if [[ "$HEALTH_CHECK" != *"healthy"* ]]; then
            echo "::error::Health check failed. API is not responding correctly."
            exit 1
          fi

          echo "API is healthy and responding correctly."
          echo "Deployment verification completed successfully."
